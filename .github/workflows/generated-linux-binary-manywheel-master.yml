# @generated DO NOT EDIT MANUALLY

# Template is at:    .github/templates/linux_binary_build_workflow.yml.j2
# Generation script: .github/scripts/generate_ci_workflows.py
name: linux-binary-manywheel

on:
  push:
    branches:
      - master
    tags:
      - 'ciflow/trunk/*'
  workflow_dispatch:

env:
  # Needed for conda builds
  ALPINE_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine"
  ANACONDA_USER: pytorch
  AWS_DEFAULT_REGION: us-east-1
  BINARY_ENV_FILE: /tmp/env
  BUILD_ENVIRONMENT: linux-binary-manywheel
  BUILDER_ROOT: /builder
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  PR_NUMBER: ${{ github.event.pull_request.number }}
  PYTORCH_FINAL_PACKAGE_DIR: /artifacts
  PYTORCH_ROOT: /pytorch
  SHA1: ${{ github.event.pull_request.head.sha || github.sha }}
  SKIP_ALL_TESTS: 1
concurrency:
  group: linux-binary-manywheel-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}
  cancel-in-progress: true

jobs:
  manywheel-py3_7-cuda10_2-build:
    if: ${{ github.repository_owner == 'pytorch' }}
    runs-on: linux.4xlarge
    timeout-minutes: 240
    env:
      PACKAGE_TYPE: manywheel
      # TODO: This is a legacy variable that we eventually want to get rid of in
      #       favor of GPU_ARCH_VERSION
      DESIRED_CUDA: cu102
      GPU_ARCH_VERSION: 10.2
      GPU_ARCH_TYPE: cuda
      DOCKER_IMAGE: pytorch/manylinux-builder:cuda10.2
      SKIP_ALL_TESTS: 1
      DESIRED_PYTHON: "3.7"
    steps:
      - name: Setup EC2 Linux
        uses: ./.github/actions/common-setup-ec2-linux
        with:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      - name: Checkout and clean PyTorch
        uses: ./.github/actions/common-checkout
        with:
          repository: pytorch/pytorch
          directory: pytorch
      - name: Checkout and clean pytorch/builder
        uses: ./.github/actions/common-checkout
        with:
          repository: pytorch/builder
          branch: main
          directory: builder
      - name: Build Linux binary
        uses: ./.github/actions/linux-binary-build
        with:
          gpu_arch_type: cuda
          gpu_arch_version: 10.2
      - uses: seemethere/upload-artifact-s3@v5
        with:
          name: manywheel-py3_7-cuda10_2
          retention-days: 14
          if-no-files-found: error
          path:
            ${{ runner.temp }}/artifacts/*
      - name: Hold runner for 2 hours or until ssh sessions have drained
        working-directory: pytorch/
        # Always hold for active ssh sessions
        if: always()
        run: .github/scripts/wait_for_ssh_to_drain.sh
      - name: Chown workspace
        if: always()
        run: |
          # Ensure the working directory gets chowned back to the current user
          docker run --rm -v "$(pwd)":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .
      - name: Kill containers, clean up images
        if: always()
        run: |
          # ignore expansion of "docker ps -q" since it could be empty
          # shellcheck disable=SC2046
          docker stop $(docker ps -q) || true
          # Prune all of the docker images
          docker system prune -af
  manywheel-py3_7-cuda10_2-test:  # Testing
    if: ${{ github.repository_owner == 'pytorch' }}
    needs: manywheel-py3_7-cuda10_2-build
    runs-on: linux.4xlarge.nvidia.gpu
    timeout-minutes: 240
    env:
      PACKAGE_TYPE: manywheel
      # TODO: This is a legacy variable that we eventually want to get rid of in
      #       favor of GPU_ARCH_VERSION
      DESIRED_CUDA: cu102
      GPU_ARCH_VERSION: 10.2
      GPU_ARCH_TYPE: cuda
      DOCKER_IMAGE: pytorch/manylinux-builder:cuda10.2
      SKIP_ALL_TESTS: 1
      DESIRED_PYTHON: "3.7"
    steps:
      - name: Setup EC2 Linux
        uses: ./.github/actions/common-setup-ec2-linux
        with:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      - uses: seemethere/download-artifact-s3@v4
        name: Download Build Artifacts
        with:
          name: manywheel-py3_7-cuda10_2
          path: "${{ runner.temp }}/artifacts/"
      - name: Checkout and clean PyTorch
        uses: ./.github/actions/common-checkout
        with:
          repository: pytorch/pytorch
          directory: pytorch
      - name: Checkout and clean pytorch/builder
        uses: ./.github/actions/common-checkout
        with:
          repository: pytorch/builder
          branch: main
          directory: builder
      - uses: nick-fields/retry@71062288b76e2b6214ebde0e673ce0de1755740a
        name: Install nvidia driver, nvidia-docker runtime, set GPU_FLAG
        with:
          timeout_minutes: 10
          max_attempts: 3
          command: |
            set -ex
            pushd pytorch
            bash .github/scripts/install_nvidia_utils_linux.sh
            echo "GPU_FLAG=--gpus all" >> "${GITHUB_ENV}"
            popd
      - name: Pull Docker image
        run: |
          retry () {
              "$@"  || (sleep 1 && "$@") || (sleep 2 && "$@")
          }
          retry docker pull "${DOCKER_IMAGE}"
      - name: Test PyTorch binary
        run: |
          set -x
          # shellcheck disable=SC2086,SC2090
          container_name=$(docker run \
            ${GPU_FLAG:-} \
            -e BINARY_ENV_FILE \
            -e BUILDER_ROOT \
            -e BUILD_ENVIRONMENT \
            -e BUILD_SPLIT_CUDA \
            -e DESIRED_CUDA \
            -e DESIRED_DEVTOOLSET \
            -e DESIRED_PYTHON \
            -e GITHUB_ACTIONS \
            -e GPU_ARCH_TYPE \
            -e GPU_ARCH_VERSION \
            -e LIBTORCH_VARIANT \
            -e PACKAGE_TYPE \
            -e PYTORCH_FINAL_PACKAGE_DIR \
            -e PYTORCH_ROOT \
            -e SKIP_ALL_TESTS \
            --tty \
            --detach \
            -v "${GITHUB_WORKSPACE}/pytorch:/pytorch" \
            -v "${GITHUB_WORKSPACE}/builder:/builder" \
            -v "${RUNNER_TEMP}/artifacts:/final_pkgs" \
            -w / \
            "${DOCKER_IMAGE}"
          )
          docker exec -t -w "${PYTORCH_ROOT}" "${container_name}" bash -c "bash .circleci/scripts/binary_populate_env.sh"
          # Generate test script
          docker exec -t -w "${PYTORCH_ROOT}" -e OUTPUT_SCRIPT="/run.sh" "${container_name}" bash -c "bash .circleci/scripts/binary_linux_test.sh"
          docker exec -t "${container_name}" bash -c "source ${BINARY_ENV_FILE} && bash -x /run.sh"
      - name: Hold runner for 2 hours or until ssh sessions have drained
        working-directory: pytorch/
        # Always hold for active ssh sessions
        if: always()
        run: .github/scripts/wait_for_ssh_to_drain.sh
      - name: Chown workspace
        if: always()
        run: |
          # Ensure the working directory gets chowned back to the current user
          docker run --rm -v "$(pwd)":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .
      - name: Kill containers, clean up images
        if: always()
        run: |
          # ignore expansion of "docker ps -q" since it could be empty
          # shellcheck disable=SC2046
          docker stop $(docker ps -q) || true
          # Prune all of the docker images
          docker system prune -af
